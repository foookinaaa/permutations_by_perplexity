{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBIS + Simulated annealing (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:27:21.103615Z",
     "iopub.status.busy": "2024-12-22T19:27:21.103283Z",
     "iopub.status.idle": "2024-12-22T19:27:26.095554Z",
     "shell.execute_reply": "2024-12-22T19:27:26.094627Z",
     "shell.execute_reply.started": "2024-12-22T19:27:21.103584Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gc\n",
    "from itertools import chain\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:27:26.097293Z",
     "iopub.status.busy": "2024-12-22T19:27:26.096903Z",
     "iopub.status.idle": "2024-12-22T19:30:10.239926Z",
     "shell.execute_reply": "2024-12-22T19:30:10.239056Z",
     "shell.execute_reply.started": "2024-12-22T19:27:26.097264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8208c63ddbe4ff9a41372f2e3330df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model /kaggle/input/gemma-2/transformers/gemma-2-9b/2\n"
     ]
    }
   ],
   "source": [
    "T.set_grad_enabled(False)\n",
    "\n",
    "model_name = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\" #\"gpt2\"\n",
    "\n",
    "b = 16 #16 #32 #64 #128\n",
    "B = 512\n",
    "max_steps = 1024\n",
    "patience = 128\n",
    "\n",
    "loss_fct = T.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "DEVICE = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                torch_dtype = T.float16 if DEVICE.type == 'cuda' else T.float32,\n",
    "                device_map='auto')\n",
    "model.eval()\n",
    "\n",
    "# words from tokenizer\n",
    "vocab = tokenizer.get_vocab()\n",
    "vocab = {vocab[i]:i for i in vocab}\n",
    "V = len(vocab)\n",
    "\n",
    "# first symbol should be english letter\n",
    "unbreakable = np.zeros((V,))\n",
    "for v in range(V):\n",
    "    unbreakable[v] = vocab[v][0].lower() in 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "print(f'Loaded model {model_name}')\n",
    "\n",
    "def shuffle(s):\n",
    "\n",
    "    with T.no_grad():\n",
    "        sentence = tokenizer(\n",
    "                    s,\n",
    "                    return_tensors='pt',\n",
    "                    add_special_tokens=False,)\n",
    "        before = tokenizer(tokenizer.bos_token, return_tensors='pt',\n",
    "                    add_special_tokens=False,)\n",
    "        after = tokenizer(tokenizer.eos_token, return_tensors='pt',\n",
    "                    add_special_tokens=False,)\n",
    "    \n",
    "        mask = (1-unbreakable[sentence['input_ids']])\n",
    "        mask[0] = 1\n",
    "\n",
    "        sentence = {k: v.to(DEVICE) for k, v in sentence.items()}\n",
    "        before = {k: v.to(DEVICE) for k, v in before.items()}\n",
    "        after = {k: v.to(DEVICE) for k, v in after.items()}\n",
    "                                        \n",
    "        for nch, k in enumerate(ibis(model, DEVICE, before, sentence, after, b, B, max_steps, patience, False, mask)):\n",
    "            if nch==0: \n",
    "                starting = k.item()\n",
    "                print('Original order NLL = ', starting)\n",
    "            else:\n",
    "                print(k[0], k[1], k[2], tokenizer.decode(k[3][1:-1], clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:30:27.693578Z",
     "iopub.status.busy": "2024-12-22T19:30:27.692728Z",
     "iopub.status.idle": "2024-12-22T19:30:27.726302Z",
     "shell.execute_reply": "2024-12-22T19:30:27.725443Z",
     "shell.execute_reply.started": "2024-12-22T19:30:27.693542Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(model, model_inputs, debug=False):\n",
    "    with T.no_grad():\n",
    "        if debug:\n",
    "            print(model_inputs)\n",
    "        # Forward pass through the model\n",
    "        outputs = model(**model_inputs, use_cache=False)\n",
    "        logits = outputs['logits'] # batch_size, 15, 256000\n",
    "\n",
    "        lsm = -logits.log_softmax(dim=-1)\n",
    "        preds = T.zeros_like(lsm)\n",
    "        preds[:,1:] = lsm[:,:-1]\n",
    "\n",
    "        shift_logits = logits[..., :-1, :].contiguous() \n",
    "        shift_labels = model_inputs['input_ids'][..., 1:].contiguous()  \n",
    "        \n",
    "        loss = loss_fct(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)),\n",
    "            shift_labels.view(-1)\n",
    "        )\n",
    "        loss = loss.view(len(logits), -1)\n",
    "        sequence_loss = loss.mean(dim=1)\n",
    "        ppl = T.exp(sequence_loss.float())\n",
    "\n",
    "        word_scores = preds.gather(2, model_inputs['input_ids'].unsqueeze(2)).squeeze(2)\n",
    "        sequence_scores = word_scores.sum(dim=1)\n",
    "        # Return sequence scores, word-level scores, and negative log probabilities\n",
    "        return ppl.cpu(), word_scores.cpu(), -preds.cpu()\n",
    "\n",
    "\n",
    "cand_orders = { 3: [[1,3,2,4]], \n",
    "                4: [[1,4,3,2,5]], \n",
    "                5: [[1,3,2,5,4,6],[1,3,5,2,4,6],[1,3,5,4,2,6],[1,4,2,5,3,6],[1,4,3,5,2,6],[1,5,4,3,2,6],[1,5,2,4,3,6],[1,5,3,2,4,6]] }\n",
    "\n",
    "\n",
    "def shuffle_proposals(mat, topk, bs, kopt):\n",
    "    \"\"\"\n",
    "    mat: A 2D tensor representing pairwise scores or relationships between sequence elements.\n",
    "    topk: The number of top candidate proposals to evaluate.\n",
    "    bs: Batch size; the number of proposals to return.\n",
    "    kopt: Number of tokens to shuffle. Determines the complexity of reshuffling.\n",
    "    \"\"\"\n",
    "    # Length of the sequence (number of tokens).\n",
    "    L = mat.shape[0]\n",
    "    # tensor for kopt number of index permutations\n",
    "    I = T.zeros((kopt,)+(L,)*(kopt)).long()\n",
    "    for i in range(kopt):\n",
    "        I[i] = T.arange(L).view((-1,) + (1,)*(kopt-1-i))\n",
    "    # A boolean tensor that ensures the selected indices are in strictly increasing order\n",
    "    # This avoids duplicate or invalid combinations, as each token can only appear once\n",
    "    mask = (0 < I[0]) \n",
    "    for i in range(kopt-1):\n",
    "        mask *= (I[i] < I[i+1])\n",
    "    lv = mat.view(-1)\n",
    "    orders = cand_orders[kopt]\n",
    "    # randomly selected shuffle order from cand_orders\n",
    "    o = np.array(orders[np.random.randint(len(orders))])\n",
    "    # the score for the proposed new order (based on o)\n",
    "    then = T.zeros((L,)*kopt)\n",
    "    # The score for the current order of tokens\n",
    "    now = T.zeros_like(then)\n",
    "    for i in range(kopt):\n",
    "        now += lv[ L*I[i] + I[i] ]\n",
    "        then += lv[ L*I[o[i]-1] + I[o[i+1]-2] ]\n",
    "    # The score improvement (positive indicates a better proposal).\n",
    "    A = then - now\n",
    "    # Invalid combinations (those not passing the mask) are heavily penalized\n",
    "    A[~mask] = -1001\n",
    "\n",
    "    # Finds the top topk reshuffling proposals based on score differences (A)\n",
    "    topv, topi = A.view(-1).topk(min(A.numel(), topk))\n",
    "    # Randomly selects bs indices from the top topk proposals for batching\n",
    "    indices = np.random.randint(topi.shape[0],size=(bs,))\n",
    "    topv = topv[indices]\n",
    "    topi = topi[indices]\n",
    "    \n",
    "    orders = [o] * bs\n",
    "    # Extracts the indices for each token\n",
    "    imod = [(topi//L**(kopt-1-i))%L for i in range(kopt)]\n",
    "\n",
    "    # Stacks the indices into a tensor of shape (bs, kopt) -> The indices for the shuffled proposals\n",
    "    # Scores of the selected proposals\n",
    "    # The reshuffling order used for each proposal.\n",
    "    return T.stack(imod,-1), topv, orders\n",
    "\n",
    "\n",
    "def ibis(model, device, before, sentence, after, bs, topk, its, patience, warminit=False, gluemask=None):\n",
    "    sent = sentence\n",
    "    # bos + sentence + eos tokens\n",
    "    padded = {\n",
    "    'input_ids': T.cat([before['input_ids'], sent['input_ids'], after['input_ids']], dim=1),  \n",
    "    'attention_mask': T.cat([before['attention_mask'], sent['attention_mask'], after['attention_mask']], dim=1)\n",
    "    }\n",
    "    # print(padded)\n",
    "    zz = score(model, padded)\n",
    "    # Total score for sentence\n",
    "    # orscore = zz[0][0]\n",
    "    orscore = zz[0]\n",
    "    yield orscore\n",
    "\n",
    "    # Total score for sentence\n",
    "    # bestscore = zz[0][0] \n",
    "    bestscore = zz[0]\n",
    "    # minus shifts the log probability scores by one position forward\n",
    "    bestsc = zz[2][0]\n",
    "\n",
    "    # indexes of the last token\n",
    "    lfix,rfix,blanks=before['input_ids'].shape[0]-1,after['input_ids'].shape[0]-1,0\n",
    "    # create bs number of lists with tokens: bos + sentence + eos\n",
    "    permsents = [T.cat([before['input_ids'], sent['input_ids'], after['input_ids']], dim=1).cpu().squeeze() for _ in range(bs) ]\n",
    "    # True for each token in bos + sentence + eos\n",
    "    bestmask = np.full(permsents[0].shape, True)\n",
    "    # put custom gluemask instead of bestmask for sentence tokens (not include eos and bos, they always True)\n",
    "    if gluemask is not None: bestmask[lfix+1:-rfix-1] = gluemask\n",
    "    # create bs number of bestmask\n",
    "    permmasks = [ bestmask.copy() for _ in range(bs) ]\n",
    "\n",
    "    # if warminit=False\n",
    "    if not warminit:\n",
    "        # all True tokens + last token in sentence\n",
    "        seg = list(np.nonzero(bestmask[lfix+1:-rfix-1])[0]) + [ len(sent['input_ids'][0]) ]\n",
    "        for b in range(1, bs):\n",
    "            # permutate seg -> tokens that we agreed to permutate is True\n",
    "            perm = np.random.permutation(len(seg)-1)\n",
    "            # permuted sentence segments\n",
    "            ns = []\n",
    "            # permuted mask segments\n",
    "            nm = []\n",
    "            for i in range(len(seg)-1):\n",
    "                # Extracts the tokens corresponding to the ith randomly selected segment\n",
    "                ns.append(sent['input_ids'][0].cpu()[seg[perm[i]]:seg[perm[i]+1]])\n",
    "                # Extracts the mask for the same segment\n",
    "                nm.append(bestmask[lfix+1:-rfix-1][seg[perm[i]]:seg[perm[i]+1]])\n",
    "            # Updates the bth sentence and mask in the batch\n",
    "            # Concatenates the permuted sentence segments (ns) into a single tensor.\n",
    "            permsents[b][lfix+1:-rfix-1] = T.cat( ns, 0 )\n",
    "            permmasks[b][lfix+1:-rfix-1] = np.concatenate( nm, 0 )\n",
    "    # lists with permuted tokens, len = bs \n",
    "    padded = T.stack(permsents,0).to(device)\n",
    "    bestsent = np.zeros(padded[0].shape)\n",
    "    bestscore = 100000000000000000 \n",
    "    movetype = 'init'\n",
    "    # Counts the number of improvements made during the process\n",
    "    nch = 0\n",
    "    # Array to hold indices of tokens considered for modification\n",
    "    candidates = np.array([1]*bs)\n",
    "    # Keeps track of the iteration at which the last improvement occurred\n",
    "    last_imp = 0\n",
    "\n",
    "    # repeat for max_steps\n",
    "    for it in range(its):  \n",
    "        padded_batch = pad_sequence(padded, batch_first=True, padding_value=0)\n",
    "        attention_mask = T.zeros_like(padded_batch)\n",
    "        attention_mask[padded_batch != 0] = 1\n",
    "    \n",
    "        model_inputs = {\n",
    "            'input_ids': padded_batch,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "        gc.collect()  \n",
    "        # if current step minus last step with inprovement score is more than patience, break\n",
    "        if it - last_imp > patience: \n",
    "            break\n",
    "\n",
    "        sc, wsc, spr = score(model, model_inputs)\n",
    "        # At the first iteration 0, the word scores (bestwsc) are saved for reference\n",
    "        if it == 0: \n",
    "            bestwsc = wsc[0] \n",
    "        # list of scores for each token\n",
    "        sc = sc.numpy()\n",
    "        # sc = np.array([t.item() for t in sc], dtype=np.float16)\n",
    "        # if score for any sequence of tokens lower than best score before\n",
    "        if sc.min() < bestscore:\n",
    "            # update best\n",
    "            if it == 0 or np.any(permsents[sc.argmin()] != bestsent):\n",
    "                nch += 1 \n",
    "                # The sequence corresponding to the lowest score in the batch\n",
    "                bestsent = permsents[sc.argmin()]\n",
    "                bestscore = sc.min()\n",
    "                bestsc = spr[sc.argmin()]\n",
    "                bestwsc = wsc[sc.argmin()]\n",
    "                bestmask = permmasks[sc.argmin()]\n",
    "    \n",
    "                if type(bestsent)==T.Tensor: \n",
    "                    bestsent = bestsent.numpy()\n",
    "                \n",
    "                last_imp = it\n",
    "                # step, 'init', ...\n",
    "                yield (it, movetype, bestscore, bestsent, bestmask)\n",
    "\n",
    "        thespr = bestsc\n",
    "        kopt = np.random.randint(3,6)\n",
    "        # Probabilities used to select candidate tokens for modification\n",
    "        cutprobs = np.ones_like(bestwsc)\n",
    "        # Tokens outside the mask (bestmask == False) are not considered\n",
    "        cutprobs[~bestmask] = 0.\n",
    "        # Boundary tokens (e.g., bos and eos) have higher probabilities to ensure stability\n",
    "        cutprobs[lfix] = 100\n",
    "        cutprobs[-1-rfix] = 100\n",
    "\n",
    "        # Global search for tokens to modify\n",
    "        # if the sequence length exceeds 6 tokens\n",
    "        if it%2 == 0 and len(bestsent)-lfix-rfix > 6:\n",
    "            # Number of candidates to select\n",
    "            ncand = bestmask[lfix:len(bestsent)-rfix].sum()\n",
    "            # limit number of candidates to select to 40 or 20\n",
    "            if kopt == 4: ncand = min(40,ncand)\n",
    "            if kopt == 5: ncand = min(20,ncand)  \n",
    "            l,r = lfix, len(bestsent)-rfix\n",
    "            # Selects ncand indices from the range [lfix, len(bestsent)-rfix], probabilities are normalized from cutprobs\n",
    "            candidates = np.random.choice(np.arange(l,r), replace=False, p=cutprobs[l:r]/cutprobs[l:r].sum(), size=(ncand,))\n",
    "            candidates.sort()\n",
    "            movetype=f'GS {kopt}'\n",
    "        else: \n",
    "            # Local search focuses on a small portion of the sequence.\n",
    "            # Performed on odd iterations (it%2 != 0) or when the sequence length <= 6\n",
    "            # Randomly determines the length of the local window (7-15 tokens)\n",
    "            ropt = np.random.randint(7,15)\n",
    "            try:\n",
    "                start = np.random.randint(lfix+1, len(bestsent)-ropt-rfix)\n",
    "                l,r = start,start+ropt\n",
    "                candidates = np.random.choice(np.arange(l,r), replace=False, p=cutprobs[l:r]/cutprobs[l:r].sum(), size=(min(ropt,(cutprobs[l:r]>0).sum()),))\n",
    "            except:\n",
    "                ropt = min(15,len(bestsent)-lfix-rfix-2)\n",
    "                start = np.random.randint(lfix+1,max(lfix+2,len(bestsent)-ropt-rfix))\n",
    "                l,r = start,start+ropt\n",
    "                candidates = np.random.choice(np.arange(l,r), replace=False, p=cutprobs[l:r]/cutprobs[l:r].sum(), size=(min(ropt,(cutprobs[l:r]>0).sum()),))\n",
    "            candidates.sort()\n",
    "            movetype=f'LS {kopt}'\n",
    "\n",
    "        # Calculates the pairwise scores between candidate tokens using the shifted probabilities.\n",
    "        # thespr: The shifted probabilities (log probabilities shifted by one position) for the sequence. It is used to calculate pairwise scores between candidates.\n",
    "        # bestsent[candidates]: Extracts the indices of tokens in bestsent that are selected as candidates.\n",
    "        links = thespr[:,bestsent[candidates]][candidates]\n",
    "        permsents = []\n",
    "        permmasks = []\n",
    "        # i: Indices of tokens for each proposal.\n",
    "        # v: Scores for the proposals.\n",
    "        # o: The shuffle orders applied to the candidates.\n",
    "        i,v,o = shuffle_proposals(links, topk, bs, kopt)\n",
    "        \n",
    "        for j in range(bs):\n",
    "            # bos + shuffled sequense + eos\n",
    "            inds = [candidates[0]] + list(candidates[i[j]]) + [candidates[-1]]\n",
    "            # Only process proposals with valid scores\n",
    "            if v[j] > -1000:\n",
    "                # Start with the portion of the sequence before the first candidate\n",
    "                pieces = [bestsent[:inds[0]]]\n",
    "                maskpieces = [bestmask[:inds[0]]]\n",
    "                for k in range(kopt+1):\n",
    "                    # Append shuffled segments\n",
    "                    pieces.append(bestsent[inds[o[j][k]-1]:inds[o[j][k]]])\n",
    "                    maskpieces.append(bestmask[inds[o[j][k]-1]:inds[o[j][k]]])\n",
    "                # Add the portion of the sequence after the last candidate\n",
    "                pieces.append(bestsent[inds[-1]:])\n",
    "                newsent = np.concatenate(pieces,0)\n",
    "                maskpieces.append(bestmask[inds[-1]:])\n",
    "                newmask = np.concatenate(maskpieces,0)\n",
    "            # If the proposal is invalid, keep the original sequence and mask\n",
    "            else: newsent, newmask = bestsent, bestmask\n",
    "                \n",
    "            permsents.append(newsent)\n",
    "            permmasks.append(newmask)\n",
    "\n",
    "        padded = T.stack(list(map(T.from_numpy,permsents)),0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:30:29.268003Z",
     "iopub.status.busy": "2024-12-22T19:30:29.267268Z",
     "iopub.status.idle": "2024-12-22T19:30:29.284548Z",
     "shell.execute_reply": "2024-12-22T19:30:29.283859Z",
     "shell.execute_reply.started": "2024-12-22T19:30:29.267975Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/ibis-sub/submission_ibis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T18:42:13.796621Z",
     "iopub.status.busy": "2024-12-22T18:42:13.795890Z",
     "iopub.status.idle": "2024-12-22T18:54:42.751247Z",
     "shell.execute_reply": "2024-12-22T18:54:42.750530Z",
     "shell.execute_reply.started": "2024-12-22T18:42:13.796588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order NLL =  549.2720336914062\n",
      "0 init 549.27203 reindeer mistletoe elf and the scrooge gingerbread chimney fireplace ornament advent family night sleep walk drive laugh jump give bake\n",
      "55 GS 5 540.75635 reindeer mistletoe elf and the scrooge gingerbread chimney fireplace ornament advent family night sleep drive walk jump laugh give bake\n",
      "73 GS 3 534.4563 reindeer mistletoe elf and the scrooge gingerbread chimney fireplace ornament advent family night sleep drive walk jump bake laugh give\n"
     ]
    }
   ],
   "source": [
    "shuffle(df.loc[1, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T18:56:59.497974Z",
     "iopub.status.busy": "2024-12-22T18:56:59.497046Z",
     "iopub.status.idle": "2024-12-22T19:05:23.607210Z",
     "shell.execute_reply": "2024-12-22T19:05:23.606463Z",
     "shell.execute_reply.started": "2024-12-22T18:56:59.497935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order NLL =  308.1136779785156\n",
      "0 init 308.11368 magi yuletide cheer grinch carol holiday holly jingle naughty nice polar workshop chimney sleigh beard nutcracker ornament decorations gifts stocking\n"
     ]
    }
   ],
   "source": [
    "shuffle(df.loc[2, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:09:40.448291Z",
     "iopub.status.busy": "2024-12-22T19:09:40.447414Z",
     "iopub.status.idle": "2024-12-22T19:16:47.730412Z",
     "shell.execute_reply": "2024-12-22T19:16:47.729604Z",
     "shell.execute_reply.started": "2024-12-22T19:09:40.448216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order NLL =  267.69378662109375\n",
      "0 init 267.6938 ornament yuletide holiday the of decorations and gifts is unwrap magi carol sing holly jingle relax eat cheer cheer grinch naughty nice visit sleigh polar beard workshop chimney stocking nutcracker\n",
      "7 GS 3 254.43936 ornament yuletide is holiday the of decorations and gifts unwrap magi carol sing holly jingle relax eat cheer cheer grinch naughty nice visit sleigh polar beard workshop chimney stocking nutcracker\n",
      "13 GS 3 240.89833 ornament yuletide is holiday the of decorations and gifts unwrap carol sing holly jingle relax eat cheer cheer grinch naughty nice visit sleigh polar beard workshop chimney stocking nutcracker magi\n",
      "23 GS 3 236.23894 ornament yuletide is holiday the of decorations and gifts holly unwrap carol sing jingle relax eat cheer cheer grinch naughty nice visit sleigh polar beard workshop chimney stocking nutcracker magi\n"
     ]
    }
   ],
   "source": [
    "shuffle(df.loc[3, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:17:47.904953Z",
     "iopub.status.busy": "2024-12-22T19:17:47.904134Z",
     "iopub.status.idle": "2024-12-22T19:27:00.846897Z",
     "shell.execute_reply": "2024-12-22T19:27:00.846181Z",
     "shell.execute_reply.started": "2024-12-22T19:17:47.904919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order NLL =  126.44959259033203\n",
      "0 init 126.44959 eggnog the season of peace and joy hope wish dream believe in wonder merry that not as we have it to you from with wrapping paper bow greeting card game night puzzle toy doll cookie milk chocolate peppermint candy fruitcake wreath poinsettia star angel snowglobe candle fireplace hohoho kaggle workshop\n"
     ]
    }
   ],
   "source": [
    "shuffle(df.loc[4, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T19:30:32.469191Z",
     "iopub.status.busy": "2024-12-22T19:30:32.468179Z",
     "iopub.status.idle": "2024-12-22T20:04:21.395283Z",
     "shell.execute_reply": "2024-12-22T20:04:21.394147Z",
     "shell.execute_reply.started": "2024-12-22T19:30:32.469156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order NLL =  50.89107131958008\n",
      "0 init 50.79177 poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie chimney chimney fireplace fireplace stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts card greeting wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice night night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle\n",
      "99 GS 3 50.495037 poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie chimney chimney fireplace fireplace stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts greeting card wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice night night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle\n",
      "221 GS 3 50.200027 poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts greeting card wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice chimney chimney fireplace fireplace night night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle\n",
      "303 GS 3 50.00432 poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts greeting card wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice chimney fireplace fireplace chimney night night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle\n",
      "352 LS 4 49.615185 poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts greeting card wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice chimney fireplace night chimney fireplace night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle\n"
     ]
    }
   ],
   "source": [
    "shuffle(df.loc[5, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T20:09:30.355936Z",
     "iopub.status.busy": "2024-12-22T20:09:30.355074Z",
     "iopub.status.idle": "2024-12-22T20:09:30.399202Z",
     "shell.execute_reply": "2024-12-22T20:09:30.398296Z",
     "shell.execute_reply.started": "2024-12-22T20:09:30.355901Z"
    }
   },
   "outputs": [],
   "source": [
    "T.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T20:09:31.129584Z",
     "iopub.status.busy": "2024-12-22T20:09:31.129296Z",
     "iopub.status.idle": "2024-12-22T20:09:31.136121Z",
     "shell.execute_reply": "2024-12-22T20:09:31.135274Z",
     "shell.execute_reply.started": "2024-12-22T20:09:31.129558Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[0, 'text'] = 'reindeer mistletoe elf scrooge gingerbread chimney fireplace ornament family advent'\n",
    "df.loc[1, 'text'] = 'reindeer mistletoe elf and the scrooge gingerbread chimney fireplace ornament advent family night sleep drive walk jump bake laugh give'\n",
    "df.loc[2, 'text'] = 'magi yuletide cheer grinch carol holiday holly jingle naughty nice polar workshop chimney sleigh beard nutcracker ornament decorations gifts stocking'\n",
    "df.loc[3, 'text'] = 'ornament yuletide is holiday the of decorations and gifts holly unwrap carol sing jingle relax eat cheer cheer grinch naughty nice visit sleigh polar beard workshop chimney stocking nutcracker magi'\n",
    "df.loc[4, 'text'] = 'eggnog the season of peace and joy hope wish dream believe in wonder merry that not as we have it to you from with wrapping paper bow greeting card game night puzzle toy doll cookie milk chocolate peppermint candy fruitcake wreath poinsettia star angel snowglobe candle fireplace hohoho kaggle workshop'\n",
    "df.loc[5, 'text'] = 'poinsettia yuletide eggnog milk chocolate peppermint candy fruitcake mistletoe holly wreath gingerbread cookie stocking hohoho laugh cheer jump sing bake walk drive visit eat sleep relax unwrap give to and from the and the and the of of as in is you that it we with have not family holiday season decorations gifts greeting card wrapping paper bow toy doll game puzzle ornament ornament nutcracker scrooge grinch snowglobe sleigh reindeer polar beard elf workshop workshop naughty nice chimney fireplace night chimney fireplace night wish dream hope believe wonder magi star angel advent candle carol joy peace cheer merry jingle kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T20:09:34.302720Z",
     "iopub.status.busy": "2024-12-22T20:09:34.301810Z",
     "iopub.status.idle": "2024-12-22T20:12:04.576642Z",
     "shell.execute_reply": "2024-12-22T20:12:04.575808Z",
     "shell.execute_reply.started": "2024-12-22T20:09:34.302684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6e9b943c914ce8a7f3e1dc8719ffee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metric import PerplexityCalculator\n",
    "scorer = PerplexityCalculator('/kaggle/input/gemma-2/transformers/gemma-2-9b/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T20:12:04.579079Z",
     "iopub.status.busy": "2024-12-22T20:12:04.578499Z",
     "iopub.status.idle": "2024-12-22T20:12:04.589239Z",
     "shell.execute_reply": "2024-12-22T20:12:04.588437Z",
     "shell.execute_reply.started": "2024-12-22T20:12:04.579039Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "temp_start = 10.0    #how high a temperature we start with (prior 10)\n",
    "temp_end = 0.5       #final temperature (prior 0.2)\n",
    "cooling_rate = 0.95  #how quick we cool each time we drop temp (prior 0.95)\n",
    "steps_per_temp = 20 #5  #steps at each temperature (prior 20)    <---- Increase this for a longer run (20 steps is about 3 hours)\n",
    "\n",
    "def simulated_annealing_optimize(text: str, temp_start=temp_start, temp_end=temp_end, cooling_rate=cooling_rate, steps_per_temp=steps_per_temp, verbose=False):\n",
    "    \"\"\"Optimize word sequence using simulated annealing, handling NaN scores by randomizing.\n",
    "\n",
    "    Args:\n",
    "       text: Input string of space-separated words to optimize\n",
    "       temp_start: Starting temperature - higher means more random exploration\n",
    "       temp_end: Ending temperature - lower means more selective at end\n",
    "       cooling_rate: How fast temperature decreases each step\n",
    "       steps_per_temp: How many swaps to try at each temperature\n",
    "       verbose: Whether to print detailed progress\n",
    "    \"\"\"\n",
    "    \n",
    "    words = text.split()\n",
    "\n",
    "    current = words.copy()\n",
    "    current_score = scorer.get_perplexity(' '.join(current))\n",
    "\n",
    "    # Handling any NaNs...\n",
    "    if math.isnan(current_score):\n",
    "        # Keep shuffling until we find a valid sequence\n",
    "        while True:\n",
    "            current = words.copy()\n",
    "            random.shuffle(current)\n",
    "            current_score = scorer.get_perplexity(' '.join(current))\n",
    "            if not math.isnan(current_score):\n",
    "                break\n",
    "            \n",
    "    best = current.copy()\n",
    "    best_score = current_score\n",
    "    temp = temp_start\n",
    "    print(f\"Start Temperature: {temp:.2f}, Initial score: {current_score:.2f}\")\n",
    "    \n",
    "    # Main annealing loop - keep trying until we've cooled down enough\n",
    "    while temp > temp_end:\n",
    "        for _ in range(steps_per_temp):  # Do multiple attempts at each temperature\n",
    "            # Try improving sequence by swapping random pairs of words\n",
    "            i, j = random.sample(range(len(words)), 2)\n",
    "            neighbor = current.copy()\n",
    "            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\n",
    "            \n",
    "            # Get score for this arrangement, skip if invalid\n",
    "            neighbor_score = scorer.get_perplexity(' '.join(neighbor))\n",
    "            if math.isnan(neighbor_score):\n",
    "                continue\n",
    "            \n",
    "            # Accept better scores, sometimes accept worse ones based on temperature\n",
    "            delta = neighbor_score - current_score\n",
    "            if delta < 0 or random.random() < math.exp(-delta / temp):\n",
    "                current = neighbor\n",
    "                current_score = neighbor_score\n",
    "                \n",
    "                if current_score < best_score:\n",
    "                    best = current.copy()\n",
    "                    best_score = current_score\n",
    "                    print(\">\", end=\"\")\n",
    "                else: print(\"<\", end=\"\")\n",
    "            else:print(\"-\", end=\"\")\n",
    "\n",
    "        \n",
    "        # Reduce temperature according to cooling schedule (AFTER all steps at this temperature)\n",
    "        temp *= cooling_rate\n",
    "        if verbose: print(f\"\\nTemperature: {temp:.2f}, Current score: {current_score:.2f}\")\n",
    "    \n",
    "    print(f\"\\nFinal score: {best_score:.2f}, {best}\")\n",
    "    \n",
    "    return ' '.join(best), best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T20:12:04.590612Z",
     "iopub.status.busy": "2024-12-22T20:12:04.590295Z",
     "iopub.status.idle": "2024-12-22T23:21:51.177839Z",
     "shell.execute_reply": "2024-12-22T23:21:51.177009Z",
     "shell.execute_reply.started": "2024-12-22T20:12:04.590587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sample 0...\n",
      "Start Temperature: 10.00, Initial score: 496.23\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Final score: 496.23, ['reindeer', 'mistletoe', 'elf', 'scrooge', 'gingerbread', 'chimney', 'fireplace', 'ornament', 'family', 'advent']\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing sample 1...\n",
      "Start Temperature: 10.00, Initial score: 536.55\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Final score: 536.55, ['reindeer', 'mistletoe', 'elf', 'and', 'the', 'scrooge', 'gingerbread', 'chimney', 'fireplace', 'ornament', 'advent', 'family', 'night', 'sleep', 'drive', 'walk', 'jump', 'bake', 'laugh', 'give']\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing sample 2...\n",
      "Start Temperature: 10.00, Initial score: 308.11\n",
      "---------<-----------------------------------------------------------------------------------------------------<---------------<------------------------------------------------------------<----<--------------------------<-<----------------<-------<------------<----------------------------------------------------------------------------------------<---------------------------------------------------------------------------------------------------------------<---------------------------------------------------------------------<------<------<------<---------------------------<----------<-------------------------------------------------------------------------------------------------------------------------------------------<----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<-----------------------------------------------------------------------------------------------------<-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Final score: 308.11, ['magi', 'yuletide', 'cheer', 'grinch', 'carol', 'holiday', 'holly', 'jingle', 'naughty', 'nice', 'polar', 'workshop', 'chimney', 'sleigh', 'beard', 'nutcracker', 'ornament', 'decorations', 'gifts', 'stocking']\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing sample 3...\n",
      "Start Temperature: 10.00, Initial score: 236.24\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<-----------------------------------------------------------------------------------------------------------------------------------------------------------<------------------------<-------------------------------------------------<---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<-----------------------------------------------------------------------------\n",
      "Final score: 236.24, ['ornament', 'yuletide', 'is', 'holiday', 'the', 'of', 'decorations', 'and', 'gifts', 'holly', 'unwrap', 'carol', 'sing', 'jingle', 'relax', 'eat', 'cheer', 'cheer', 'grinch', 'naughty', 'nice', 'visit', 'sleigh', 'polar', 'beard', 'workshop', 'chimney', 'stocking', 'nutcracker', 'magi']\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing sample 4...\n",
      "Start Temperature: 10.00, Initial score: 126.45\n",
      "-----------------------------------<---------------<---------------<---------------<--------------<------<--<----------------<-----------<----------------------------------<-------------<<---------------------------------<-----------------------<-----------<-------<-----------------------------------------------------------------------<---<---------------------<<---------------------------------------------<-<--------------<<-------------------------------------------------------------------------<----<------------------------<-----<-----<-----------------------------------<------------------------------<---------------------------------------------------<------------<-------------------------------------------------------<----------------------------------------------<-----------<----------------------------<<-----<------------------------------------------------------------------------------------------------------<------------------------------------------------------------------<----------<--------------------------------<-------------------------------------------------------------------------------------------------<----------------------------------------\n",
      "Final score: 126.45, ['eggnog', 'the', 'season', 'of', 'peace', 'and', 'joy', 'hope', 'wish', 'dream', 'believe', 'in', 'wonder', 'merry', 'that', 'not', 'as', 'we', 'have', 'it', 'to', 'you', 'from', 'with', 'wrapping', 'paper', 'bow', 'greeting', 'card', 'game', 'night', 'puzzle', 'toy', 'doll', 'cookie', 'milk', 'chocolate', 'peppermint', 'candy', 'fruitcake', 'wreath', 'poinsettia', 'star', 'angel', 'snowglobe', 'candle', 'fireplace', 'hohoho', 'kaggle', 'workshop']\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing sample 5...\n",
      "Start Temperature: 10.00, Initial score: 49.62\n",
      "------<<<---<<---<-----<<--<-<<--<---<--<--------<---<---<-<<<<-----------<----------<--<------<------<----------------<----<--<---------<<--<-----<-------<---<<-----<-----<-<<---<------<----<--------<-<--<<-<-<----<-------------<------<-----<--<<--<--<--<------<----<-<<----<---<---<---<--<<------<--------<-<<------------<-<<--<---<--------<---<<--------<---<--------------<-----<<---------------<------------<-----<<---<---<-----<-------<-<---------<--<----------<----<<-<---------<<----<<-------<---------------<-<--<-----------------<--------<--------<---------------------<-----------------------<--------<----------<--<------<---<-----------<--------<-----<----<---------<<--------------<-<-----<-------------------------<<--------------<---<---------<-<-------------------------<--------<------------------<-----------<----------<----<----------------------------<---<------------------------------<------------------------------------------------------------<<------------<-----<<---------<-----------<---<--------------------<-<<-----<---------------------------------<------------------------<-------------<--------------------------------------------------------------\n",
      "Final score: 49.62, ['poinsettia', 'yuletide', 'eggnog', 'milk', 'chocolate', 'peppermint', 'candy', 'fruitcake', 'mistletoe', 'holly', 'wreath', 'gingerbread', 'cookie', 'stocking', 'hohoho', 'laugh', 'cheer', 'jump', 'sing', 'bake', 'walk', 'drive', 'visit', 'eat', 'sleep', 'relax', 'unwrap', 'give', 'to', 'and', 'from', 'the', 'and', 'the', 'and', 'the', 'of', 'of', 'as', 'in', 'is', 'you', 'that', 'it', 'we', 'with', 'have', 'not', 'family', 'holiday', 'season', 'decorations', 'gifts', 'greeting', 'card', 'wrapping', 'paper', 'bow', 'toy', 'doll', 'game', 'puzzle', 'ornament', 'ornament', 'nutcracker', 'scrooge', 'grinch', 'snowglobe', 'sleigh', 'reindeer', 'polar', 'beard', 'elf', 'workshop', 'workshop', 'naughty', 'nice', 'chimney', 'fireplace', 'night', 'chimney', 'fireplace', 'night', 'wish', 'dream', 'hope', 'believe', 'wonder', 'magi', 'star', 'angel', 'advent', 'candle', 'carol', 'joy', 'peace', 'cheer', 'merry', 'jingle', 'kaggle']\n",
      "--------------------------------------------------\n",
      "\n",
      "Score Summary:\n",
      "Submission mean score: 292.20\n",
      "\n",
      "Submission file created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>reindeer mistletoe elf scrooge gingerbread chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reindeer mistletoe elf and the scrooge gingerb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>magi yuletide cheer grinch carol holiday holly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ornament yuletide is holiday the of decoration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>eggnog the season of peace and joy hope wish d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>poinsettia yuletide eggnog milk chocolate pepp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  reindeer mistletoe elf scrooge gingerbread chi...\n",
       "1   1  reindeer mistletoe elf and the scrooge gingerb...\n",
       "2   2  magi yuletide cheer grinch carol holiday holly...\n",
       "3   3  ornament yuletide is holiday the of decoration...\n",
       "4   4  eggnog the season of peace and joy hope wish d...\n",
       "5   5  poinsettia yuletide eggnog milk chocolate pepp..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=['id', 'text'])\n",
    "scores = []\n",
    "\n",
    "# Process each sample\n",
    "for idx, row in df.iterrows():\n",
    "   print(f\"\\nProcessing sample {idx}...\")\n",
    "   optimized, score = simulated_annealing_optimize(row.text)\n",
    "   scores.append(score)\n",
    "   \n",
    "   # Add to submission dataframe\n",
    "   submission.loc[idx] = {\n",
    "       'id': row.id,\n",
    "       'text': optimized\n",
    "   }\n",
    "   print(\"-\" * 50)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nScore Summary:\")\n",
    "print(f\"Submission mean score: {np.mean(scores):.2f}\")\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"submission_simulated_annealing_ibis.csv\", index=False)\n",
    "print(\"\\nSubmission file created!\")\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10229277,
     "sourceId": 88046,
     "sourceType": "competition"
    },
    {
     "datasetId": 6306987,
     "sourceId": 10205739,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6354612,
     "sourceId": 10270641,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6355830,
     "sourceId": 10272290,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 209577560,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 76277,
     "modelInstanceId": 72255,
     "sourceId": 104492,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
